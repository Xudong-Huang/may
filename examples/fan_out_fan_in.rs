/// # Fan-Out/Fan-In Pattern Example
///
/// ## Description
/// This example demonstrates the fan-out/fan-in pattern using May coroutines.
/// Work is distributed across multiple worker coroutines (fan-out) and results
/// are aggregated back into a single stream (fan-in).
///
/// ## Architecture
/// ```text
/// [Work Queue] ‚Üí [Distributor] ‚Üí [Worker 1] ‚îê
///                              ‚Üí [Worker 2] ‚îú‚îÄ‚Üí [Aggregator] ‚Üí [Results]
///                              ‚Üí [Worker 3] ‚îò
/// ```
///
/// ## Use Cases
/// - Parallel processing of independent tasks
/// - Load balancing across multiple workers
/// - Map-reduce style computations
/// - Concurrent API calls or database operations
///
/// ## Performance Characteristics
/// - Configurable number of worker coroutines
/// - Work distribution across multiple workers
/// - Graceful handling of worker failures
/// - Comprehensive metrics and monitoring
///
/// ## Usage
/// ```bash
/// cargo run --example fan_out_fan_in
/// cargo run --example fan_out_fan_in -- --workers 8 --tasks 1000 --work-complexity 100
/// ```

#[macro_use]
extern crate may;

use may::coroutine;
use may::sync::mpsc;
use rand;
use std::collections::HashMap;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};

/// Configuration for the fan-out/fan-in example
#[derive(Debug, Clone, Copy)]
struct FanOutConfig {
    num_workers: usize,
    num_tasks: usize,
    work_complexity: u64,
    enable_failures: bool,
    failure_rate: f64,
    work_distribution_strategy: WorkDistributionStrategy,
}

#[derive(Debug, Clone, Copy)]
enum WorkDistributionStrategy {
    RoundRobin,
    Random,
}

impl Default for FanOutConfig {
    fn default() -> Self {
        Self {
            num_workers: 4,
            num_tasks: 100,
            work_complexity: 50,
            enable_failures: false,
            failure_rate: 0.02,
            work_distribution_strategy: WorkDistributionStrategy::RoundRobin,
        }
    }
}

/// Work item to be processed by workers
#[derive(Debug, Clone)]
struct WorkItem {
    id: u64,
    data: Vec<u8>,
    complexity: u64,
    created_at: Instant,
}

/// Result of processing a work item
#[derive(Debug, Clone)]
struct WorkResult {
    id: u64,
    worker_id: usize,
    result_data: HashMap<String, String>,
    processing_time: Duration,
    created_at: Instant,
    completed_at: Instant,
}

/// Worker statistics for monitoring
#[derive(Debug, Default)]
struct WorkerStats {
    tasks_processed: AtomicU64,
    tasks_failed: AtomicU64,
    total_processing_time: AtomicU64,
    idle_time: AtomicU64,
}

impl WorkerStats {
    fn increment_processed(&self) {
        self.tasks_processed.fetch_add(1, Ordering::Relaxed);
    }

    fn increment_failed(&self) {
        self.tasks_failed.fetch_add(1, Ordering::Relaxed);
    }

    fn add_processing_time(&self, duration: Duration) {
        self.total_processing_time
            .fetch_add(duration.as_millis() as u64, Ordering::Relaxed);
    }

    fn add_idle_time(&self, duration: Duration) {
        self.idle_time
            .fetch_add(duration.as_millis() as u64, Ordering::Relaxed);
    }

    fn get_stats(&self) -> (u64, u64, u64, u64) {
        (
            self.tasks_processed.load(Ordering::Relaxed),
            self.tasks_failed.load(Ordering::Relaxed),
            self.total_processing_time.load(Ordering::Relaxed),
            self.idle_time.load(Ordering::Relaxed),
        )
    }
}

/// Overall system metrics
#[derive(Debug)]
struct SystemMetrics {
    worker_stats: Vec<WorkerStats>,
    distributor_stats: WorkerStats,
    aggregator_stats: WorkerStats,
    start_time: Instant,
}

impl SystemMetrics {
    fn new(num_workers: usize) -> Self {
        Self {
            worker_stats: (0..num_workers).map(|_| WorkerStats::default()).collect(),
            distributor_stats: WorkerStats::default(),
            aggregator_stats: WorkerStats::default(),
            start_time: Instant::now(),
        }
    }

    fn print_summary(&self) {
        let total_time = self.start_time.elapsed();

        println!("\n=== Fan-Out/Fan-In Processing Summary ===");
        println!("Total Runtime: {:.2}s", total_time.as_secs_f64());

        // Worker statistics
        println!("\nWorker Statistics:");
        let mut total_processed = 0;
        let mut total_failed = 0;
        let mut total_work_time = 0;

        for (i, stats) in self.worker_stats.iter().enumerate() {
            let (processed, failed, work_time, idle_time) = stats.get_stats();
            total_processed += processed;
            total_failed += failed;
            total_work_time += work_time;

            let avg_time = if processed > 0 {
                work_time / processed
            } else {
                0
            };
            let utilization = if work_time + idle_time > 0 {
                (work_time as f64 / (work_time + idle_time) as f64) * 100.0
            } else {
                0.0
            };

            println!(
                "Worker {:2} | Processed: {:>6} | Failed: {:>4} | Avg: {:>4}ms | Util: {:>5.1}%",
                i, processed, failed, avg_time, utilization
            );
        }

        // Aggregated statistics
        let (dist_processed, dist_failed, dist_time, _) = self.distributor_stats.get_stats();
        let (agg_processed, agg_failed, agg_time, _) = self.aggregator_stats.get_stats();

        println!("\nSystem Statistics:");
        println!(
            "Distributor   | Processed: {:>6} | Failed: {:>4} | Total Time: {:>6}ms",
            dist_processed, dist_failed, dist_time
        );
        println!(
            "Aggregator    | Processed: {:>6} | Failed: {:>4} | Total Time: {:>6}ms",
            agg_processed, agg_failed, agg_time
        );

        // Overall metrics
        let success_rate = if total_processed + total_failed > 0 {
            (total_processed as f64 / (total_processed + total_failed) as f64) * 100.0
        } else {
            0.0
        };

        let throughput = total_processed as f64 / total_time.as_secs_f64();
        let avg_worker_time = if total_processed > 0 {
            total_work_time / total_processed
        } else {
            0
        };

        println!("\nOverall Performance:");
        println!(
            "Success Rate: {:.2}% | Throughput: {:.2} tasks/sec | Avg Processing: {}ms",
            success_rate, throughput, avg_worker_time
        );
    }
}

/// Work distributor - fans out work to multiple workers
fn work_distributor(
    config: FanOutConfig,
    work_senders: Vec<mpsc::Sender<WorkItem>>,
    metrics: Arc<SystemMetrics>,
) {
    println!("üîÑ Starting Work Distributor...");

    let mut next_worker = 0;
    let mut work_count = 0;

    // Create work items
    for i in 0..config.num_tasks {
        let start_time = Instant::now();

        // Create work item with varying complexity
        let complexity = config.work_complexity + (i as u64 % 50);
        let data_size = (complexity / 10) as usize;

        let work_item = WorkItem {
            id: i as u64,
            data: vec![0u8; data_size],
            complexity,
            created_at: start_time,
        };

        // Distribute work based on strategy
        let target_worker = match config.work_distribution_strategy {
            WorkDistributionStrategy::RoundRobin => {
                let worker = next_worker;
                next_worker = (next_worker + 1) % config.num_workers;
                worker
            }
            WorkDistributionStrategy::Random => rand::random::<usize>() % config.num_workers,
        };

        // Send work to selected worker
        if let Err(_) = work_senders[target_worker].send(work_item) {
            println!("‚ùå Distributor: Worker {} disconnected", target_worker);
            metrics.distributor_stats.increment_failed();
            continue;
        }

        work_count += 1;
        metrics.distributor_stats.increment_processed();
        metrics
            .distributor_stats
            .add_processing_time(start_time.elapsed());

        // Progress reporting
        if work_count % (config.num_tasks / 10).max(1) == 0 {
            println!(
                "üì§ Distributor: Sent {}/{} work items",
                work_count, config.num_tasks
            );
        }
    }

    // Signal completion by closing all work channels
    for sender in work_senders {
        drop(sender);
    }

    println!(
        "‚úÖ Work Distributor completed - {} items distributed",
        work_count
    );
}

/// Worker coroutine - processes work items
fn worker(
    worker_id: usize,
    config: FanOutConfig,
    work_rx: mpsc::Receiver<WorkItem>,
    result_tx: mpsc::Sender<WorkResult>,
    metrics: Arc<SystemMetrics>,
) {
    println!("üîÑ Starting Worker {}...", worker_id);

    let worker_stats = &metrics.worker_stats[worker_id];
    let mut processed_count = 0;

    while let Ok(work_item) = work_rx.recv() {
        let processing_start = Instant::now();

        // Simulate work processing
        let work_duration = Duration::from_millis(work_item.complexity);
        coroutine::sleep(work_duration);

        // Simulate processing failures
        if config.enable_failures && rand::random::<f64>() < config.failure_rate {
            println!(
                "‚ö†Ô∏è  Worker {}: Failed to process item {}",
                worker_id, work_item.id
            );
            worker_stats.increment_failed();
            continue;
        }

        // Process the work item
        let mut result_data = HashMap::new();
        result_data.insert("worker_id".to_string(), worker_id.to_string());
        result_data.insert("data_size".to_string(), work_item.data.len().to_string());
        result_data.insert("complexity".to_string(), work_item.complexity.to_string());
        result_data.insert(
            "processing_time_ms".to_string(),
            work_duration.as_millis().to_string(),
        );

        // Add some computed results
        let checksum: u32 = work_item
            .data
            .iter()
            .enumerate()
            .map(|(i, &b)| (i as u32 + b as u32) * work_item.complexity as u32)
            .sum();
        result_data.insert("checksum".to_string(), checksum.to_string());

        let work_result = WorkResult {
            id: work_item.id,
            worker_id,
            result_data,
            processing_time: processing_start.elapsed(),
            created_at: work_item.created_at,
            completed_at: Instant::now(),
        };

        // Send result
        if let Err(_) = result_tx.send(work_result) {
            println!("‚ùå Worker {}: Result channel disconnected", worker_id);
            worker_stats.increment_failed();
            return;
        }

        processed_count += 1;
        worker_stats.increment_processed();
        worker_stats.add_processing_time(processing_start.elapsed());

        // Periodic progress reporting
        if processed_count % 50 == 0 {
            println!(
                "ÔøΩÔøΩ Worker {}: Processed {} items",
                worker_id, processed_count
            );
        }
    }

    println!(
        "‚úÖ Worker {} completed - {} items processed",
        worker_id, processed_count
    );
}

/// Result aggregator - fans in results from all workers
fn result_aggregator(
    config: FanOutConfig,
    result_rx: mpsc::Receiver<WorkResult>,
    metrics: Arc<SystemMetrics>,
) {
    println!("üîÑ Starting Result Aggregator...");

    let mut results = Vec::new();
    let mut worker_counts = HashMap::new();
    let mut total_processing_time = Duration::new(0, 0);

    while let Ok(result) = result_rx.recv() {
        let start_time = Instant::now();

        // Aggregate result statistics
        let worker_count = worker_counts.entry(result.worker_id).or_insert(0);
        *worker_count += 1;

        total_processing_time += result.processing_time;

        // Store result for final analysis
        results.push(result);

        metrics.aggregator_stats.increment_processed();
        metrics
            .aggregator_stats
            .add_processing_time(start_time.elapsed());

        // Progress reporting
        if results.len() % (config.num_tasks / 10).max(1) == 0 {
            println!(
                "üì• Aggregator: Collected {}/{} results",
                results.len(),
                config.num_tasks
            );
        }
    }

    // Final result analysis
    println!("\n=== Result Analysis ===");
    println!("Total Results Collected: {}", results.len());

    // Worker distribution analysis
    println!("\nWork Distribution:");
    for (worker_id, count) in worker_counts.iter() {
        let percentage = (*count as f64 / results.len() as f64) * 100.0;
        println!("Worker {}: {} tasks ({:.1}%)", worker_id, count, percentage);
    }

    // Timing analysis
    if !results.is_empty() {
        let avg_processing_time = total_processing_time / results.len() as u32;
        let min_time = results.iter().map(|r| r.processing_time).min().unwrap();
        let max_time = results.iter().map(|r| r.processing_time).max().unwrap();

        println!("\nProcessing Time Analysis:");
        println!(
            "Average: {:.2}ms | Min: {:.2}ms | Max: {:.2}ms",
            avg_processing_time.as_secs_f64() * 1000.0,
            min_time.as_secs_f64() * 1000.0,
            max_time.as_secs_f64() * 1000.0
        );
    }

    // End-to-end latency analysis
    let end_to_end_times: Vec<Duration> = results
        .iter()
        .map(|r| r.completed_at.duration_since(r.created_at))
        .collect();

    if !end_to_end_times.is_empty() {
        let avg_e2e = end_to_end_times.iter().sum::<Duration>() / end_to_end_times.len() as u32;
        let min_e2e = end_to_end_times.iter().min().unwrap();
        let max_e2e = end_to_end_times.iter().max().unwrap();

        println!("\nEnd-to-End Latency:");
        println!(
            "Average: {:.2}ms | Min: {:.2}ms | Max: {:.2}ms",
            avg_e2e.as_secs_f64() * 1000.0,
            min_e2e.as_secs_f64() * 1000.0,
            max_e2e.as_secs_f64() * 1000.0
        );
    }

    println!(
        "‚úÖ Result Aggregator completed - {} results processed",
        results.len()
    );
}

/// Parse command line arguments
fn parse_args() -> FanOutConfig {
    let args: Vec<String> = std::env::args().collect();
    let mut config = FanOutConfig::default();

    let mut i = 1;
    while i < args.len() {
        match args[i].as_str() {
            "--workers" => {
                if i + 1 < args.len() {
                    config.num_workers = args[i + 1].parse().unwrap_or(config.num_workers);
                    i += 1;
                }
            }
            "--tasks" => {
                if i + 1 < args.len() {
                    config.num_tasks = args[i + 1].parse().unwrap_or(config.num_tasks);
                    i += 1;
                }
            }
            "--work-complexity" => {
                if i + 1 < args.len() {
                    config.work_complexity = args[i + 1].parse().unwrap_or(config.work_complexity);
                    i += 1;
                }
            }
            "--enable-failures" => {
                config.enable_failures = true;
            }
            "--failure-rate" => {
                if i + 1 < args.len() {
                    config.failure_rate = args[i + 1].parse().unwrap_or(config.failure_rate);
                    i += 1;
                }
            }
            "--strategy" => {
                if i + 1 < args.len() {
                    config.work_distribution_strategy = match args[i + 1].as_str() {
                        "round-robin" => WorkDistributionStrategy::RoundRobin,
                        "random" => WorkDistributionStrategy::Random,
                        _ => config.work_distribution_strategy,
                    };
                    i += 1;
                }
            }
            "--help" => {
                println!("Fan-Out/Fan-In Pattern Example");
                println!("Usage: cargo run --example fan_out_fan_in [OPTIONS]");
                println!("Options:");
                println!("  --workers <N>           Number of worker coroutines [default: 4]");
                println!("  --tasks <N>             Number of tasks to process [default: 100]");
                println!("  --work-complexity <N>   Work complexity (processing time in ms) [default: 50]");
                println!("  --enable-failures       Enable random failures in workers");
                println!("  --failure-rate <RATE>   Failure rate (0.0-1.0) [default: 0.02]");
                println!("  --strategy <STRATEGY>   Distribution strategy: round-robin, random [default: round-robin]");
                println!("  --help                  Show this help message");
                std::process::exit(0);
            }
            _ => {}
        }
        i += 1;
    }

    config
}

fn main() {
    let config = parse_args();

    println!("üöÄ Starting Fan-Out/Fan-In Pattern Example");
    println!("Configuration: {:?}", config);

    // Configure May runtime
    may::config().set_workers(config.num_workers.max(2));

    let start_time = Instant::now();
    let metrics = Arc::new(SystemMetrics::new(config.num_workers));

    // Run the fan-out/fan-in pattern within a coroutine scope
    may::coroutine::scope(|scope| {
        // Create channels for work distribution
        let mut work_senders = Vec::new();
        let mut work_receivers = Vec::new();

        for _ in 0..config.num_workers {
            let (tx, rx) = mpsc::channel();
            work_senders.push(tx);
            work_receivers.push(rx);
        }

        // Create channel for result aggregation
        let (result_tx, result_rx) = mpsc::channel();

        // Spawn work distributor
        let work_senders_clone = work_senders.clone();
        let metrics_clone = metrics.clone();
        go!(scope, move || {
            work_distributor(config, work_senders_clone, metrics_clone);
        });

        // Spawn worker coroutines
        for worker_id in 0..config.num_workers {
            let work_rx = work_receivers.pop().unwrap();
            let result_tx_clone = result_tx.clone();
            let metrics_clone = metrics.clone();
            go!(scope, move || {
                worker(worker_id, config, work_rx, result_tx_clone, metrics_clone);
            });
        }

        // Drop the original result sender so aggregator knows when to stop
        drop(result_tx);

        // Spawn result aggregator
        let metrics_clone = metrics.clone();
        go!(scope, move || {
            result_aggregator(config, result_rx, metrics_clone);
        });

        // Progress monitor
        let metrics_clone = metrics.clone();
        go!(scope, move || {
            let mut last_completed = 0;
            loop {
                coroutine::sleep(Duration::from_secs(2));

                let completed = metrics_clone
                    .aggregator_stats
                    .tasks_processed
                    .load(Ordering::Relaxed);
                if completed >= config.num_tasks as u64 {
                    break;
                }

                if completed > last_completed {
                    let rate = (completed - last_completed) as f64 / 2.0;
                    println!(
                        "üìä Progress: {}/{} tasks completed ({:.1} tasks/sec)",
                        completed, config.num_tasks, rate
                    );
                    last_completed = completed;
                }
            }
        });
    });

    let total_time = start_time.elapsed();

    // Print comprehensive metrics
    metrics.print_summary();

    println!("\n‚ú® Fan-Out/Fan-In Pattern Example completed successfully!");
    println!("üéØ Total execution time: {:.2}s", total_time.as_secs_f64());
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_fan_out_config_default() {
        let config = FanOutConfig::default();
        assert_eq!(config.num_workers, 4);
        assert_eq!(config.num_tasks, 100);
        assert_eq!(config.work_complexity, 50);
        assert!(!config.enable_failures);
    }

    #[test]
    fn test_worker_stats() {
        let stats = WorkerStats::default();

        stats.increment_processed();
        stats.increment_processed();
        stats.increment_failed();
        stats.add_processing_time(Duration::from_millis(100));
        stats.add_idle_time(Duration::from_millis(50));

        let (processed, failed, work_time, idle_time) = stats.get_stats();
        assert_eq!(processed, 2);
        assert_eq!(failed, 1);
        assert_eq!(work_time, 100);
        assert_eq!(idle_time, 50);
    }

    #[test]
    fn test_small_fan_out_fan_in() {
        may::config().set_workers(2);

        let config = FanOutConfig {
            num_workers: 2,
            num_tasks: 5,
            work_complexity: 1,
            enable_failures: false,
            failure_rate: 0.0,
            work_distribution_strategy: WorkDistributionStrategy::RoundRobin,
        };

        let metrics = Arc::new(SystemMetrics::new(config.num_workers));

        may::coroutine::scope(|scope| {
            let mut work_senders = Vec::new();
            let mut work_receivers = Vec::new();

            for _ in 0..config.num_workers {
                let (tx, rx) = mpsc::channel();
                work_senders.push(tx);
                work_receivers.push(rx);
            }

            let (result_tx, result_rx) = mpsc::channel();

            let work_senders_clone = work_senders.clone();
            let metrics_clone = metrics.clone();
            go!(scope, move || {
                work_distributor(config, work_senders_clone, metrics_clone);
            });

            for worker_id in 0..config.num_workers {
                let work_rx = work_receivers.pop().unwrap();
                let result_tx_clone = result_tx.clone();
                let metrics_clone = metrics.clone();
                go!(scope, move || {
                    worker(worker_id, config, work_rx, result_tx_clone, metrics_clone);
                });
            }

            drop(result_tx);

            let metrics_clone = metrics.clone();
            go!(scope, move || {
                result_aggregator(config, result_rx, metrics_clone);
            });
        });

        // Verify all tasks were processed
        let completed = metrics
            .aggregator_stats
            .tasks_processed
            .load(Ordering::Relaxed);
        assert_eq!(completed, 5);
    }
}
